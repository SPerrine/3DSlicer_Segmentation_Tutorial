# 3DSlicer_Segmentation_Tutorial
This is a general protocol for hand annotation of 3D image stacks for use in our machine learning segmentation protocols. This tutorial uses a 16-bit cropped, reoriented, LUT adjusted microCT, phosphotungstic acid enhanced scan dataset from the open access available data for [Susan M Motch Perrine, M Kathleen Pitirri, Emily L Durham, Mizuho Kawasaki, Hao Zheng, Danny Z Chen, Kazuhiko Kawasaki, Joan T Richtsmeier (2022) A dysmorphic mouse model reveals developmental interactions of chondrocranium and dermatocranium eLife 11:e76653.](https://doi.org/10.7554/eLife.76653) Data is available from the Penn State ScholarSphere repository Open Access Data for, ["A dysmorphic mouse model reveals developmental interactions of chondrocranium and dermatocranium"](https://scholarsphere.psu.edu/resources/44387e59-0aa7-40f7-9e2b-af4606f5fbac). Pick any of the PTA_microCT_Exx.x folders to download, and the folder "PTA_microCT_docs.zip" for scan information.

##**Directions**
1. Once you have downloaded and unzipped an appropriate 16-bit scan from the repository above, find the matching scan information, open 3DSlicer
2. Click on the "Data", then click on "Choose Directory to Add" and navigate to the data. The file path will be listed on the left, and the description should say, "Volume". Then click the "OK" button. (https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide1.PNG)
3. If you would like to visualize the data in the 3D window, left-click and drag the data name to the 3D window. You should be able to see the 3D slices. If you cannot, change the viewer set up by picking from the view options dropdown. Double click on the coronal slice view (should be the red viewer in standard 3DSlicer setup) so it is your primary view.(https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide2.PNG)
4. Right-click the dataset and choose "Segment this" in the dropdown.
5.Click "Add" to create a label field for what you want to segment (also called hand annotation for our purposes). Rename this "Cartilage". Click on the color button and find the Terminology label for cartilage and click "Select". (https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide3.PNG)
6. If you are to annotating all cartilage for an entire specimen, you will find the first slice containing cartilage and start from there, annotating the appropriate number of slices. For this tutorial, we have chosen a slice image that contains various areas of cartilage. All cartilage needs to be annotated in every slice, or the machine learning algorithms will be untrained or mis-trained.
7. Select the paintbrush tool, and carefully annotate all cartilage within the slices. The paintbrush and eraser tools are probably going to be the most useful for this purpose, but feel free to explore other tools as long as they work in 2D and not 3D - stay on the appropriate slices! (https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide4.PNG)
(https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide5.PNG)
8. Save your work frequently!
9. When completely finished and you have received approval to send the labels to be used for training our machine learning algorithms, you will have to save the labels as a .tiff stack.
10. Go back to the Data module and right-click on the "Cartilage" label field. Choose the option, "Export visible segments to binary labelmap".
(https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide6.PNG)
11. Right-click on the new cartilage label and choose "Export to file." Save as .nrrd. It's ok to compress this file. This file will need opened in Fiji and then slice images exported as a .tif stack. (https://github.com/SPerrine/3DSlicer_Segmentation_Tutorial/blob/main/images/Slide7.PNG)

